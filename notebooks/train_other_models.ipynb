{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING OUT STUFF IN THIS FILE, CAN BE DELETED WHEN WE ARE DONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "ConvCRF_dir = '../ConvCRF'\n",
    "sys.path.insert(0,ConvCRF_dir)\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, utils, models\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.dataloader import DatasetFloe, DatasetFloeVal  # Init signature: DatasetFloe(patch_size: int, batch_size: int, mode='train')\n",
    "from tools.loss import calc_loss          # smoothening factor for dice loss is 1e-6\n",
    "from tools.crf_conf import default_conf   # configuration for conditional random field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def model_save(model, total_iters, best_model):\n",
    "#     if best_model == 'best_model':\n",
    "#         path = '../model/weights/'+ps+'_'+arc+'_' + loss+'_BEST_.mdl'\n",
    "#     else:\n",
    "#         path = '../model/weights/'+ps+'_'+arc+'_' + str(total_iters) + 'iter'+'_'+loss+'.mdl'\n",
    "    \n",
    "#     torch.save({'state_dict':model.state_dict(),\n",
    "#             'iterations':str(total_iters),\n",
    "#             'weights':loss,\n",
    "#             'patch_size':ps\n",
    "#            }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model1, train_loader, learning_rate, weight_bce):\n",
    "    model1.cuda()\n",
    "    model1.train()\n",
    "    \n",
    "    total_iters = 0\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        for batch_idx, sample in enumerate(train_loader):\n",
    "            \n",
    "            model1.train()\n",
    "            \n",
    "            X = sample['image'].cuda()\n",
    "            y = sample['mask'].cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred1 = model1(X)    # USE pred['out'] for dlv3 and fcn\n",
    "            \n",
    "            if (not(str(type(pred1)) == \"<class 'collections.OrderedDict'>\")):\n",
    "                loss = calc_loss(pred1, y[:,1,:,:].unsqueeze(1), weight_bce=weight_bce)\n",
    "            else:\n",
    "                loss = calc_loss(pred1['out'], y[:,1,:,:].unsqueeze(1), weight_bce=weight_bce)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_iters +=1\n",
    "            \n",
    "            print(\"Iteration: {}\\tCurrent loss:{:.6f}\".format(total_iters, loss.item()))\n",
    "            \n",
    "            writer.add_scalar('training', loss.item(), total_iters)\n",
    "            writer.add_image('mask', y[:,1,:,:].unsqueeze(1), total_iters, dataformats='NCHW')\n",
    "            if (not(str(type(pred1)) == \"<class 'collections.OrderedDict'>\")):\n",
    "                writer.add_image('prediction', torch.sigmoid(pred1)[:,0,:,:].unsqueeze(1), total_iters, dataformats='NCHW') # torch.sigmoid(pred1)[:,1,:,:] resunet\n",
    "            else:\n",
    "                writer.add_image('prediction', torch.sigmoid(pred1['out'])[:,0,:,:].unsqueeze(1), total_iters, dataformats='NCHW')\n",
    "            \n",
    "            if(total_iters % 20 == 0):\n",
    "                model1.eval()\n",
    "                val_loss_total = []\n",
    "                with torch.no_grad():\n",
    "                    for _, sample_val in enumerate(val_loader):\n",
    "                        \n",
    "                        X_val = sample_val['image'].cuda()\n",
    "                        y_val = sample_val['mask'].cuda()\n",
    "                        pred1_val = model1(X_val)    # USE pred['out'] for dlv3 and fcn\n",
    "            \n",
    "                        if (not(str(type(pred1)) == \"<class 'collections.OrderedDict'>\")):\n",
    "                            loss_val = calc_loss(pred1_val, y_val[:,1,:,:].unsqueeze(1), weight_bce=weight_bce)\n",
    "                        else:\n",
    "                            loss_val = calc_loss(pred1_val['out'], y_val[:,1,:,:].unsqueeze(1), weight_bce=weight_bce)\n",
    "                        \n",
    "                        val_loss_total.append(loss_val.item())\n",
    "                        \n",
    "                writer.add_scalar('validation', np.mean(val_loss_total), total_iters)\n",
    "                print(\"Validation loss:{:.6f}\".format(np.mean(val_loss_total)))\n",
    "                \n",
    "            writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def train_model(model, train_loader, learning_rate, weight_bce):\n",
    "#     model.cuda()\n",
    "#     model.train()\n",
    "#     total_iters = 0\n",
    "#     best_loss = 999999\n",
    "    \n",
    "#     for i in range(n_iterations):\n",
    "#         for batch_idx, sample in enumerate(train_loader):\n",
    "#             X = sample['image'].cuda()\n",
    "#             y = sample['mask'].cuda()\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             pred = model(X)    # USE pred['out'] for dlv3 and fcn,,,,,,,, ELSE USE pred    :)\n",
    "#             loss = calc_loss(pred, y, weight_bce=weight_bce)\n",
    "# #             out = torch.sigmoid(pred)\n",
    "# #             loss = F.mse_loss(pred, y)\n",
    "# #             bce = F.binary_cross_entropy_with_logits(pred, y)\n",
    "# #             lovasz_loss = lovasz_softmax(out, y, classes=[1])\n",
    "# #             loss = weight_bce * bce + (1-weight_bce) * lovasz_loss\n",
    "    \n",
    "            \n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             scheduler.step()\n",
    "            \n",
    "#             total_iters +=1\n",
    "            \n",
    "#             print(\"Iteration: {}\\tCurrent loss:{:.6f}\".format(total_iters,loss.item()))\n",
    "            \n",
    "#             writer.add_scalar('training', loss.item(), total_iters)\n",
    "            \n",
    "#             if (total_iters % validation_counter == 0):\n",
    "#                 valid_loader =  DataLoader(valid_ds, batch_size=6, num_workers=0)\n",
    "#                 validate(model, valid_loader, total_iters, weight_bce)\n",
    "#             writer.close()\n",
    "            \n",
    "#             model.train()\n",
    "            \n",
    "# #             if(total_iters>1 and loss.item() < best_loss):\n",
    "# #                 best_loss = loss.item()\n",
    "# #                 model_save(model, total_iters, 'best_model')\n",
    "# #                 print('SAVED---------------------------->')\n",
    "            \n",
    "#         #if(total_iters % 200 == 0 and total_iters < 1000 or total_iters % 1000 == 0):\n",
    "#             #model_save(model, total_iters, 'regular_saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \"\"\"DEEPLAB V3 RESNET101\"\"\"\n",
    "\n",
    "# from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "# model1 = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "# model1.classifier = DeepLabHead(2048, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../model/weights/2_384_DLv3_200iter_MSE.mdl')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \"\"\"FCN RESNET101\"\"\"\n",
    "\n",
    "# from torchvision.models.segmentation.fcn import FCNHead\n",
    "# model = models.segmentation.fcn_resnet101(pretrained=True)\n",
    "# model.classifier = FCNHead(2048, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../model/weights/1_288_FCN_200iter_0.5BCE.mdl')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"RESUNET BACKBONE RESNET34\"\"\"\n",
    "# from model.architecture import ResUNet\n",
    "# resnet = models.resnet34(pretrained=True)\n",
    "# layers = list(resnet.children())\n",
    "# model = ResUNet(layers, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsample_blocks[0] in: 1024   out: 256\n",
      "upsample_blocks[1] in: 256   out: 128\n",
      "upsample_blocks[2] in: 128   out: 64\n",
      "upsample_blocks[3] in: 64   out: 32\n",
      "upsample_blocks[4] in: 32   out: 16\n"
     ]
    }
   ],
   "source": [
    "from backboned_unet import Unet\n",
    "# 'resnet'- 18, 34, 50, 101, 152\n",
    "# 'vgg'- 16, 19\n",
    "# 'densenet' - 121, 161, 169, 201\n",
    "\n",
    "model = Unet(backbone_name='densenet121', classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../model/weights/resUNET continuous training/288_resUNET_200iter_0.5BCE.mdl')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = '480'\n",
    "arc = 'denseUNET' #'DLv3'\n",
    "loss = '0.5BCE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_ds = DatasetFloe(patch_size= int(ps), batch_size= batch_size, mode='train')\n",
    "train_loader =  DataLoader(train_ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "val_ds = DatasetFloeVal(patch_size= int(ps),)  # ADDED LATER\n",
    "val_loader =  DataLoader(val_ds, batch_size=1, num_workers=0)  # ADDED LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 50\n",
    "learning_rate = 10e-2\n",
    "weight_bce = 1\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr= learning_rate)#,\n",
    "#         weight_decay = weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[2000],\n",
    "    gamma = 0.1\n",
    ")\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/home/muzik999/MASc/iceFloe/floes/model/weights/UNET_CRF/NEW/experiment_BACKBONE/1_480_DENSEUNET_.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tCurrent loss:0.046977\n",
      "Iteration: 2\tCurrent loss:0.031361\n",
      "Iteration: 3\tCurrent loss:0.037066\n",
      "Iteration: 4\tCurrent loss:0.047208\n",
      "Iteration: 5\tCurrent loss:0.028644\n",
      "Iteration: 6\tCurrent loss:0.014107\n",
      "Iteration: 7\tCurrent loss:0.024451\n",
      "Iteration: 8\tCurrent loss:0.039960\n",
      "Iteration: 9\tCurrent loss:0.023345\n",
      "Iteration: 10\tCurrent loss:0.023380\n",
      "Iteration: 11\tCurrent loss:0.021914\n",
      "Iteration: 12\tCurrent loss:0.032365\n",
      "Iteration: 13\tCurrent loss:0.044724\n",
      "Iteration: 14\tCurrent loss:0.023831\n",
      "Iteration: 15\tCurrent loss:0.013599\n",
      "Iteration: 16\tCurrent loss:0.046493\n",
      "Iteration: 17\tCurrent loss:0.022152\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c186f4663919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_bce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-72edf68f45e1>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(model1, train_loader, learning_rate, weight_bce)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MASc/iceFloe/floes/tools/dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_train(model, train_loader, learning_rate, weight_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/muzik999/MASc/iceFloe/floes/model/weights/UNET_CRF/NEW/2_480_DENSEUNET_.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([4, 1, 480, 480])) must be the same as input size (torch.Size([4, 2, 480, 480]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d921d4abc097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_bce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_bce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_bce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_bce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MASc/iceFloe/floes/tools/loss.py\u001b[0m in \u001b[0;36mcalc_loss\u001b[0;34m(pred, target, weight_bce)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_bce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mbce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([4, 1, 480, 480])) must be the same as input size (torch.Size([4, 2, 480, 480]))"
     ]
    }
   ],
   "source": [
    "model1.cuda()\n",
    "model1.train()\n",
    "\n",
    "total_iters = 0\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "\n",
    "        model1.train()\n",
    "\n",
    "        X = sample['image'].cuda()\n",
    "        y = sample['mask'].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred1 = model1(X)    # USE pred['out'] for dlv3 and fcn\n",
    "\n",
    "        if (not(str(type(pred1)) == \"<class 'collections.OrderedDict'>\")):\n",
    "            loss = calc_loss(pred1, y, weight_bce=weight_bce)\n",
    "        else:\n",
    "            loss = calc_loss(pred1['out'], y[:,1,:,:].unsqueeze(1), weight_bce=weight_bce)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_iters +=1\n",
    "\n",
    "        print(\"Iteration: {}\\tCurrent loss:{:.6f}\".format(total_iters, loss.item()))\n",
    "\n",
    "        writer.add_scalar('training', loss.item(), total_iters)\n",
    "        writer.add_image('mask', y[:,1,:,:].unsqueeze(1), total_iters, dataformats='NCHW')\n",
    "        if (pred1.shape[1] == 2):\n",
    "            writer.add_image('prediction', torch.sigmoid(pred1)[:,1,:,:].unsqueeze(1), total_iters, dataformats='NCHW')\n",
    "        else:\n",
    "            writer.add_image('prediction', torch.sigmoid(pred1['out'])[:,0,:,:].unsqueeze(1), total_iters, dataformats='NCHW')\n",
    "\n",
    "        if(total_iters % 20 == 0):\n",
    "            model1.eval()\n",
    "            val_loss_total = []\n",
    "            with torch.no_grad():\n",
    "                for _, sample_val in enumerate(val_loader):\n",
    "\n",
    "                    X_val = sample_val['image'].cuda()\n",
    "                    y_val = sample_val['mask'].cuda()\n",
    "                    pred1_val = model1(X_val)    # USE pred['out'] for dlv3 and fcn\n",
    "\n",
    "                    if (not(str(type(pred1)) == \"<class 'collections.OrderedDict'>\")):\n",
    "                        loss_val = calc_loss(pred1_val, y_val, weight_bce=weight_bce)\n",
    "                    else:\n",
    "                        loss_val = calc_loss(pred1['out'], y_val[:,1,:,:].unsqueeze(1), weight_bce=weight_bce)\n",
    "\n",
    "                    val_loss_total.append(loss_val.item())\n",
    "\n",
    "            writer.add_scalar('validation', np.mean(val_loss_total), total_iters)\n",
    "            print(\"Validation loss:{:.6f}\".format(np.mean(val_loss_total)))\n",
    "\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception1(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(Inception1, self).__init__()\n",
    "        self.branch1x1 = conv(in_channels, pool_features, kernel_size=1) # 1\n",
    "\n",
    "        self.branch5x5_1 = conv(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv(48, pool_features, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv(96, pool_features, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "    \n",
    "class Inception2(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(Inception2, self).__init__()\n",
    "        self.branch1x1 = conv(in_channels, pool_features, kernel_size=1) # 1\n",
    "\n",
    "        self.branch5x5_1 = conv(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv(48, pool_features, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv(96, pool_features, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class Inception3(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(Inception3, self).__init__()\n",
    "        self.branch1x1 = conv(in_channels, pool_features, kernel_size=1) # 1\n",
    "\n",
    "        self.branch5x5_1 = conv(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv(48, pool_features, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv(96, pool_features, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class Inception4(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(Inception4, self).__init__()\n",
    "        self.branch1x1 = conv(in_channels, pool_features, kernel_size=1) # 1\n",
    "\n",
    "        self.branch5x5_1 = conv(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv(48, pool_features, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv(96, pool_features, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class incepUnet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dconv_d1 = Inception1(1, 16)\n",
    "        self.dconv_d2 = Inception2(64, 32)\n",
    "        self.dconv_d3 = Inception3(128, 64)\n",
    "        self.dconv_d4 = Inception4(256, 128)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.dconv_u3 = double_conv(512 + 256, 256)  # skip connection, so adding 256\n",
    "        self.dconv_u2 = double_conv(256 + 128, 128)\n",
    "        self.dconv_u1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_classes, 1, dilation=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_d1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_d2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        conv3 = self.dconv_d3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "\n",
    "        x = self.dconv_d4(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_u3(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "\n",
    "        x = self.dconv_u2(x)\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "\n",
    "        x = self.dconv_u1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_chnls, out_chnls, kernel_size, padding=0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels = in_chnls, out_channels = out_chnls, kernel_size = kernel_size, padding = padding),\n",
    "        nn.BatchNorm2d(num_features = out_chnls),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "def double_conv(in_channels, out_channels):\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace = True),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incepUnet(\n",
       "  (dconv_d1): Inception1(\n",
       "    (branch1x1): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_1): Sequential(\n",
       "      (0): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_2): Sequential(\n",
       "      (0): Conv2d(48, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): Sequential(\n",
       "      (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): Sequential(\n",
       "      (0): Conv2d(96, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch_pool): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dconv_d2): Inception2(\n",
       "    (branch1x1): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_1): Sequential(\n",
       "      (0): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_2): Sequential(\n",
       "      (0): Conv2d(48, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): Sequential(\n",
       "      (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch_pool): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dconv_d3): Inception3(\n",
       "    (branch1x1): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_1): Sequential(\n",
       "      (0): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_2): Sequential(\n",
       "      (0): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): Sequential(\n",
       "      (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): Sequential(\n",
       "      (0): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch_pool): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dconv_d4): Inception4(\n",
       "    (branch1x1): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_1): Sequential(\n",
       "      (0): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch5x5_2): Sequential(\n",
       "      (0): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): Sequential(\n",
       "      (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): Sequential(\n",
       "      (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (branch_pool): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (dconv_u3): Sequential(\n",
       "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_u2): Sequential(\n",
       "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_u1): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incepUnet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]              32\n",
      "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
      "              ReLU-3         [-1, 16, 224, 224]               0\n",
      "            Conv2d-4         [-1, 48, 224, 224]              96\n",
      "       BatchNorm2d-5         [-1, 48, 224, 224]              96\n",
      "              ReLU-6         [-1, 48, 224, 224]               0\n",
      "            Conv2d-7         [-1, 16, 224, 224]          19,216\n",
      "       BatchNorm2d-8         [-1, 16, 224, 224]              32\n",
      "              ReLU-9         [-1, 16, 224, 224]               0\n",
      "           Conv2d-10         [-1, 64, 224, 224]             128\n",
      "      BatchNorm2d-11         [-1, 64, 224, 224]             128\n",
      "             ReLU-12         [-1, 64, 224, 224]               0\n",
      "           Conv2d-13         [-1, 96, 224, 224]          55,392\n",
      "      BatchNorm2d-14         [-1, 96, 224, 224]             192\n",
      "             ReLU-15         [-1, 96, 224, 224]               0\n",
      "           Conv2d-16         [-1, 16, 224, 224]          13,840\n",
      "      BatchNorm2d-17         [-1, 16, 224, 224]              32\n",
      "             ReLU-18         [-1, 16, 224, 224]               0\n",
      "           Conv2d-19         [-1, 16, 224, 224]              32\n",
      "      BatchNorm2d-20         [-1, 16, 224, 224]              32\n",
      "             ReLU-21         [-1, 16, 224, 224]               0\n",
      "       Inception1-22         [-1, 64, 224, 224]               0\n",
      "        MaxPool2d-23         [-1, 64, 112, 112]               0\n",
      "           Conv2d-24         [-1, 32, 112, 112]           2,080\n",
      "      BatchNorm2d-25         [-1, 32, 112, 112]              64\n",
      "             ReLU-26         [-1, 32, 112, 112]               0\n",
      "           Conv2d-27         [-1, 48, 112, 112]           3,120\n",
      "      BatchNorm2d-28         [-1, 48, 112, 112]              96\n",
      "             ReLU-29         [-1, 48, 112, 112]               0\n",
      "           Conv2d-30         [-1, 32, 112, 112]          38,432\n",
      "      BatchNorm2d-31         [-1, 32, 112, 112]              64\n",
      "             ReLU-32         [-1, 32, 112, 112]               0\n",
      "           Conv2d-33         [-1, 64, 112, 112]           4,160\n",
      "      BatchNorm2d-34         [-1, 64, 112, 112]             128\n",
      "             ReLU-35         [-1, 64, 112, 112]               0\n",
      "           Conv2d-36         [-1, 96, 112, 112]          55,392\n",
      "      BatchNorm2d-37         [-1, 96, 112, 112]             192\n",
      "             ReLU-38         [-1, 96, 112, 112]               0\n",
      "           Conv2d-39         [-1, 32, 112, 112]          27,680\n",
      "      BatchNorm2d-40         [-1, 32, 112, 112]              64\n",
      "             ReLU-41         [-1, 32, 112, 112]               0\n",
      "           Conv2d-42         [-1, 32, 112, 112]           2,080\n",
      "      BatchNorm2d-43         [-1, 32, 112, 112]              64\n",
      "             ReLU-44         [-1, 32, 112, 112]               0\n",
      "       Inception2-45        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-46          [-1, 128, 56, 56]               0\n",
      "           Conv2d-47           [-1, 64, 56, 56]           8,256\n",
      "      BatchNorm2d-48           [-1, 64, 56, 56]             128\n",
      "             ReLU-49           [-1, 64, 56, 56]               0\n",
      "           Conv2d-50           [-1, 48, 56, 56]           6,192\n",
      "      BatchNorm2d-51           [-1, 48, 56, 56]              96\n",
      "             ReLU-52           [-1, 48, 56, 56]               0\n",
      "           Conv2d-53           [-1, 64, 56, 56]          76,864\n",
      "      BatchNorm2d-54           [-1, 64, 56, 56]             128\n",
      "             ReLU-55           [-1, 64, 56, 56]               0\n",
      "           Conv2d-56           [-1, 64, 56, 56]           8,256\n",
      "      BatchNorm2d-57           [-1, 64, 56, 56]             128\n",
      "             ReLU-58           [-1, 64, 56, 56]               0\n",
      "           Conv2d-59           [-1, 96, 56, 56]          55,392\n",
      "      BatchNorm2d-60           [-1, 96, 56, 56]             192\n",
      "             ReLU-61           [-1, 96, 56, 56]               0\n",
      "           Conv2d-62           [-1, 64, 56, 56]          55,360\n",
      "      BatchNorm2d-63           [-1, 64, 56, 56]             128\n",
      "             ReLU-64           [-1, 64, 56, 56]               0\n",
      "           Conv2d-65           [-1, 64, 56, 56]           8,256\n",
      "      BatchNorm2d-66           [-1, 64, 56, 56]             128\n",
      "             ReLU-67           [-1, 64, 56, 56]               0\n",
      "       Inception3-68          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-69          [-1, 256, 28, 28]               0\n",
      "           Conv2d-70          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-71          [-1, 128, 28, 28]             256\n",
      "             ReLU-72          [-1, 128, 28, 28]               0\n",
      "           Conv2d-73           [-1, 48, 28, 28]          12,336\n",
      "      BatchNorm2d-74           [-1, 48, 28, 28]              96\n",
      "             ReLU-75           [-1, 48, 28, 28]               0\n",
      "           Conv2d-76          [-1, 128, 28, 28]         153,728\n",
      "      BatchNorm2d-77          [-1, 128, 28, 28]             256\n",
      "             ReLU-78          [-1, 128, 28, 28]               0\n",
      "           Conv2d-79           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-80           [-1, 64, 28, 28]             128\n",
      "             ReLU-81           [-1, 64, 28, 28]               0\n",
      "           Conv2d-82           [-1, 96, 28, 28]          55,392\n",
      "      BatchNorm2d-83           [-1, 96, 28, 28]             192\n",
      "             ReLU-84           [-1, 96, 28, 28]               0\n",
      "           Conv2d-85          [-1, 128, 28, 28]         110,720\n",
      "      BatchNorm2d-86          [-1, 128, 28, 28]             256\n",
      "             ReLU-87          [-1, 128, 28, 28]               0\n",
      "           Conv2d-88          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-89          [-1, 128, 28, 28]             256\n",
      "             ReLU-90          [-1, 128, 28, 28]               0\n",
      "       Inception4-91          [-1, 512, 28, 28]               0\n",
      "         Upsample-92          [-1, 512, 56, 56]               0\n",
      "           Conv2d-93          [-1, 256, 56, 56]       1,769,728\n",
      "      BatchNorm2d-94          [-1, 256, 56, 56]             512\n",
      "             ReLU-95          [-1, 256, 56, 56]               0\n",
      "           Conv2d-96          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-97          [-1, 256, 56, 56]             512\n",
      "             ReLU-98          [-1, 256, 56, 56]               0\n",
      "         Upsample-99        [-1, 256, 112, 112]               0\n",
      "          Conv2d-100        [-1, 128, 112, 112]         442,496\n",
      "     BatchNorm2d-101        [-1, 128, 112, 112]             256\n",
      "            ReLU-102        [-1, 128, 112, 112]               0\n",
      "          Conv2d-103        [-1, 128, 112, 112]         147,584\n",
      "     BatchNorm2d-104        [-1, 128, 112, 112]             256\n",
      "            ReLU-105        [-1, 128, 112, 112]               0\n",
      "        Upsample-106        [-1, 128, 224, 224]               0\n",
      "          Conv2d-107         [-1, 64, 224, 224]         110,656\n",
      "     BatchNorm2d-108         [-1, 64, 224, 224]             128\n",
      "            ReLU-109         [-1, 64, 224, 224]               0\n",
      "          Conv2d-110         [-1, 64, 224, 224]          36,928\n",
      "     BatchNorm2d-111         [-1, 64, 224, 224]             128\n",
      "            ReLU-112         [-1, 64, 224, 224]               0\n",
      "          Conv2d-113          [-1, 1, 224, 224]              65\n",
      "================================================================\n",
      "Total params: 3,957,585\n",
      "Trainable params: 3,957,585\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 855.11\n",
      "Params size (MB): 15.10\n",
      "Estimated Total Size (MB): 870.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(incepUnet(1).cuda(), (1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /home/muzik999/.cache/torch/hub/v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /home/muzik999/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n",
      "100%|██████████| 104M/104M [00:10<00:00, 10.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'inception_v3', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_layers = list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BasicConv2d(\n",
       "   (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "   (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), BasicConv2d(\n",
       "   (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), BasicConv2d(\n",
       "   (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), BasicConv2d(\n",
       "   (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), BasicConv2d(\n",
       "   (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), InceptionA(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch5x5_1): BasicConv2d(\n",
       "     (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch5x5_2): BasicConv2d(\n",
       "     (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionA(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch5x5_1): BasicConv2d(\n",
       "     (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch5x5_2): BasicConv2d(\n",
       "     (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionA(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch5x5_1): BasicConv2d(\n",
       "     (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch5x5_2): BasicConv2d(\n",
       "     (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionB(\n",
       "   (branch3x3): BasicConv2d(\n",
       "     (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "     (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionC(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_2): BasicConv2d(\n",
       "     (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_3): BasicConv2d(\n",
       "     (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_4): BasicConv2d(\n",
       "     (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_5): BasicConv2d(\n",
       "     (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionC(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_2): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_3): BasicConv2d(\n",
       "     (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_4): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_5): BasicConv2d(\n",
       "     (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionC(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_2): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_3): BasicConv2d(\n",
       "     (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_4): BasicConv2d(\n",
       "     (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_5): BasicConv2d(\n",
       "     (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionC(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_2): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7_3): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_3): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_4): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7dbl_5): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionAux(\n",
       "   (conv0): BasicConv2d(\n",
       "     (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (conv1): BasicConv2d(\n",
       "     (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       " ), InceptionD(\n",
       "   (branch3x3_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3_2): BasicConv2d(\n",
       "     (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "     (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7x3_1): BasicConv2d(\n",
       "     (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7x3_2): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7x3_3): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch7x7x3_4): BasicConv2d(\n",
       "     (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionE(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3_1): BasicConv2d(\n",
       "     (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3_2a): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3_2b): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3a): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3b): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), InceptionE(\n",
       "   (branch1x1): BasicConv2d(\n",
       "     (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3_1): BasicConv2d(\n",
       "     (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3_2a): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3_2b): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_1): BasicConv2d(\n",
       "     (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_2): BasicConv2d(\n",
       "     (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3a): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch3x3dbl_3b): BasicConv2d(\n",
       "     (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "     (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (branch_pool): BasicConv2d(\n",
       "     (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), Linear(in_features=2048, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
